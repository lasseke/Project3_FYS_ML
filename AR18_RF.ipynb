{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping the vegetation distribution in Norway using Random Forest\n",
    "### Analysis pt. 1\n",
    "Main workflow for reading the preprocessed data and setting up the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import libraries\n",
    "# Matrix/vector handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Scikit-learn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold\n",
    "# Own code\n",
    "from lib import RandomForest as rf\n",
    "from lib import Evaluation as evl\n",
    "from lib import DataHandling as dat\n",
    "from lib import Plotting as pl\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read and partition data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read confusion matrix. No need to scale or transform input data!\n",
    "X_cat = pd.read_pickle(\"./DataFiles/FeatureMatrixCats.pkl\")\n",
    "\n",
    "# Read target\n",
    "y_cat = pd.read_pickle(\"./DataFiles/TargetVTs.pkl\")\n",
    "\n",
    "### Construct final feature matrices\n",
    "# Remove variables from data frames that should not be in feature matrix\n",
    "rmvars = [\"x\",\"y\",\"plot_id\",\"geology_norge1\"]\n",
    "X_cat_final = X_cat.drop(rmvars, axis=1)\n",
    "\n",
    "print(X_cat_final.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SPLIT DATA INTO TEST AND TRAIN\n",
    "testSetRatio = 0.2    # Proportion of data that should end up in test set\n",
    "seed  = 77           # Random seed to make results reproducible\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Start with numerical scaled\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "train_test_split(X_cat_final, y_cat, test_size = testSetRatio, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scikit Learn\n",
    "sklrf = RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=15, max_features='auto',\\\n",
    "                               bootstrap=True, oob_score=True, verbose=0, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklrf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sklrf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklrf.oob_score_)\n",
    "print(sklrf.feature_importances_)\n",
    "print(sklrf.classes_)\n",
    "print(sklrf.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "r = permutation_importance(sklrf, X_test, y_test, n_repeats=5, random_state=0,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in r.importances_mean.argsort()[::-1]:\n",
    "    if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "        print(f\"{X_cat_final.columns[i]:<20}\" f\"{r.importances_mean[i]:.3f}\" f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create cross validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "### Create cross validation folds\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "split_idx = kf.split(X_cat_final)\n",
    "\n",
    "### Initialize empty lists\n",
    "MODELS = []\n",
    "cat_acc_cv, prec_cv, rec_cv, f1_cv, auc_cv = [],[],[],[],[]\n",
    "cat_acc_cv_test, prec_cv_test, rec_cv_test, f1_cv_test, auc_cv_test = [],[],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.precision_score(y_test,y_pred,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "### Loop through folds\n",
    "for train_index, test_index in split_idx:\n",
    "    \n",
    "    ### Subset data to current fold\n",
    "    X_train_cur = X_cat_final.iloc[train_index,:]\n",
    "    y_train_cur = y_cat.iloc[train_index]\n",
    "    \n",
    "    X_test_cur = X_cat_final.iloc[test_index,:]\n",
    "    y_test_cur = y_cat.iloc[test_index]\n",
    "    \n",
    "    ### Scikit Learn\n",
    "    rf_cur = RandomForestClassifier(n_estimators=500, criterion='gini', max_depth=18, max_features='auto',\\\n",
    "                                    bootstrap=True, oob_score=True, verbose=0, n_jobs=-1)\n",
    "    rf_cur.fit(X_train_cur, y_train_cur)\n",
    "    y_pred_cur = rf_cur.predict(X_test_cur)\n",
    "    \n",
    "    \n",
    "    # Out of bag\n",
    "    cat_acc_cv.append(rf_cur.oob_score_)\n",
    "    #prec_cv.append(metrics.precision_score(y_test_cur, y_pred_cur, average='macro'))\n",
    "    #rec_cv.append(metrics.recall_score(y_test_cur, y_pred_cur, average='macro'))\n",
    "    #f1_cv.append(metrics.f1_score(y_test_cur, y_pred_cur, average='macro'))\n",
    "    #auc_cv.append(metrics.roc_auc_score(y_test_cur, y_pred_cur, average='macro'))\n",
    "    \n",
    "    ### Test set\n",
    "    cat_acc_cv_test.append(metrics.accuracy_score(y_test_cur, y_pred_cur))\n",
    "    prec_cv_test.append(metrics.precision_score(y_test_cur, y_pred_cur, average='macro'))\n",
    "    rec_cv_test.append(metrics.recall_score(y_test_cur, y_pred_cur, average='macro'))\n",
    "    f1_cv_test.append(metrics.f1_score(y_test_cur, y_pred_cur, average='macro'))\n",
    "    #auc_cv_test.append(metrics.roc_auc_score(y_test_cur, y_pred_cur, average='macro',multi_class='ovo'))\n",
    "    \n",
    "    MODELS.append(rf_cur)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2 = sklrf.predict(X_test_cur)\n",
    "metrics.accuracy_score(y_test_cur, y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train = pd.DataFrame(data={\"categorical_accuracy\": cat_acc_cv, \"precision\": prec_cv, \"recall\": rec_cv, \"auc\": auc_cv, \"f1_score\": f1_cv})\n",
    "df_test = pd.DataFrame(data={\"categorical_accuracy\": cat_acc_cv_test, \"precision\": prec_cv_test, \"recall\": rec_cv_test, \"f1_score\": f1_cv_test})\n",
    "\n",
    "#df_train.to_csv(\"./Results/Tables/NN_trainmetrics.csv\", sep=',',index=False)\n",
    "df_test.to_csv(\"./Results/Tables/RF_testmetrics.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot a tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "fn=X_train.columns\n",
    "cn=sklrf.classes_\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=300)\n",
    "t = tree.plot_tree(sklrf.estimators_[0],\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               filled = True,\n",
    "              max_depth=1,\n",
    "              fontsize=3.5,\n",
    "              precision=2,proportion=False);\n",
    "#fig.savefig('Results/FigureFiles/RF_treeExample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 10))\n",
    "corr = spearmanr(X_cat_final).correlation\n",
    "corr_linkage = hierarchy.ward(corr)\n",
    "dendro = hierarchy.dendrogram(\n",
    "    corr_linkage, labels=X_cat_final.columns.tolist(), ax=ax1, leaf_rotation=90\n",
    ")\n",
    "dendro_idx = np.arange(0, len(dendro['ivl']))\n",
    "\n",
    "ax2.imshow(corr[dendro['leaves'], :][:, dendro['leaves']])\n",
    "ax2.set_xticks(dendro_idx)\n",
    "ax2.set_yticks(dendro_idx)\n",
    "ax2.set_xticklabels(dendro['ivl'], rotation='vertical')\n",
    "ax2.set_yticklabels(dendro['ivl'])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "cluster_ids = hierarchy.fcluster(corr_linkage, 1, criterion='distance')\n",
    "cluster_id_to_feature_ids = defaultdict(list)\n",
    "for idx, cluster_id in enumerate(cluster_ids):\n",
    "    cluster_id_to_feature_ids[cluster_id].append(idx)\n",
    "'''\n",
    "cluster_id_to_feature_ids contains clusters of correlated variables as seperate lists.\n",
    "Size of lists is determined by \"k\", the second input of hierarchy.fcluster.\n",
    "Higher k --> more correlation required to end up in same list\n",
    "'''\n",
    "selected_features = [v[0] for v in cluster_id_to_feature_ids.values()]\n",
    "\n",
    "X_train_sel = X_train.iloc[:, selected_features]\n",
    "X_test_sel = X_test.iloc[:, selected_features]\n",
    "\n",
    "clf_sel = RandomForestClassifier(n_estimators=500, random_state=42,n_jobs=-1)\n",
    "clf_sel.fit(X_train_sel, y_train)\n",
    "print(\"Accuracy on test data with features removed: {:.2f}\".format(\n",
    "      clf_sel.score(X_test_sel, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_id_to_feature_ids.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in cluster_id_to_feature_ids.values():\n",
    "    print(X_train.columns[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "r_sub = permutation_importance(clf_sel, X_test_sel, y_test, n_repeats=5, random_state=0,n_jobs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in r_sub.importances_mean.argsort()[::-1]:\n",
    "    if r_sub.importances_mean[i] - 2 * r_sub.importances_std[i] > 0:\n",
    "        print(f\"{X_train_sel.columns[i]:<20}\" f\"{r_sub.importances_mean[i]:.3f}\" f\" +/- {r_sub.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read metrics, plot for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rf = pd.read_csv('./Results/Tables/RF_testmetrics.csv')\n",
    "data_nn = pd.read_csv('./Results/Tables/NN_testmetrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nn = data_nn.drop(['auc'],axis=1)\n",
    "labels = ['Accuracy', 'Precision', 'Recall', 'F1-score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nn.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.metricsBoxPlot(data_rf, data_nn, ticks=labels, fig_size=(10,8), _save=False, savename=\"MetricsCompariRFvsNN.png\",\\\n",
    "                  title='Comparison of classification metrics - 5 fold cv\\n Random Forest vs. Deep Neural Network',\\\n",
    "                  name_data_1='RandomForest', name_data_2='DeepNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data_nn))\n",
    "print(data_nn.shape)\n",
    "np.array(range(len(data_nn)))*2.0-0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(data_nn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
